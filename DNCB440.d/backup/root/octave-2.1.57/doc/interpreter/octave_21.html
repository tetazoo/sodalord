<HTML>
<HEAD>
<!-- Created by texi2html 1.56k from octave.texi on 15 March 2004 -->

<TITLE>GNU Octave - Linear Algebra</TITLE>
</HEAD>
<BODY>
Go to the <A HREF="octave_1.html">first</A>, <A HREF="octave_20.html">previous</A>, <A HREF="octave_22.html">next</A>, <A HREF="octave_45.html">last</A> section, <A HREF="octave_toc.html">table of contents</A>.
<P><HR><P>


<H1><A NAME="SEC156" HREF="octave_toc.html#TOC156">Linear Algebra</A></H1>

<P>
This chapter documents the linear algebra functions of Octave.
Reference material for many of these functions may be found in
Golub and Van Loan, <CITE>Matrix Computations, 2nd Ed.</CITE>, Johns Hopkins,
1989, and in <CITE>LAPACK Users' Guide</CITE>, SIAM, 1992.




<H2><A NAME="SEC157" HREF="octave_toc.html#TOC157">Basic Matrix Functions</A></H2>

<P>
@anchor{doc-balance}
<DL>
<DT><U>Loadable Function:</U> <VAR>aa</VAR> = <B>balance</B> <I>(<VAR>a</VAR>, <VAR>opt</VAR>)</I>
<DD><A NAME="IDX792"></A>
<DT><U>Loadable Function:</U> [<VAR>dd</VAR>, <VAR>aa</VAR>] = <B>balance</B> <I>(<VAR>a</VAR>, <VAR>opt</VAR>)</I>
<DD><A NAME="IDX793"></A>
<DT><U>Loadable Function:</U> [<VAR>cc</VAR>, <VAR>dd</VAR>, <VAR>aa</VAR>, <VAR>bb</VAR>] = <B>balance</B> <I>(<VAR>a</VAR>, <VAR>b</VAR>, <VAR>opt</VAR>)</I>
<DD><A NAME="IDX794"></A>


<P>
<CODE>[dd, aa] = balance (a)</CODE> returns <CODE>aa = dd \ a * dd</CODE>.
<CODE>aa</CODE> is a matrix whose row and column norms are roughly equal in
magnitude, and <CODE>dd</CODE> = <CODE>p * d</CODE>, where <CODE>p</CODE> is a permutation
matrix and <CODE>d</CODE> is a diagonal matrix of powers of two.  This allows
the equilibration to be computed without roundoff.  Results of
eigenvalue calculation are typically improved by balancing first.


<P>
<CODE>[cc, dd, aa, bb] = balance (a, b)</CODE> returns <CODE>aa = cc*a*dd</CODE> and
<CODE>bb = cc*b*dd)</CODE>, where <CODE>aa</CODE> and <CODE>bb</CODE> have non-zero
elements of approximately the same magnitude and <CODE>cc</CODE> and <CODE>dd</CODE>
are permuted diagonal matrices as in <CODE>dd</CODE> for the algebraic
eigenvalue problem.


<P>
The eigenvalue balancing option <CODE>opt</CODE> is selected as follows:


<DL COMPACT>

<DT><CODE>"N"</CODE>, <CODE>"n"</CODE>
<DD>
No balancing; arguments copied, transformation(s) set to identity.

<DT><CODE>"P"</CODE>, <CODE>"p"</CODE>
<DD>
Permute argument(s) to isolate eigenvalues where possible.

<DT><CODE>"S"</CODE>, <CODE>"s"</CODE>
<DD>
Scale to improve accuracy of computed eigenvalues.

<DT><CODE>"B"</CODE>, <CODE>"b"</CODE>
<DD>
Permute and scale, in that order. Rows/columns of a (and b)
that are isolated by permutation are not scaled.  This is the default
behavior.
</DL>

<P>
Algebraic eigenvalue balancing uses standard LAPACK routines.


<P>
Generalized eigenvalue problem balancing uses Ward's algorithm
(SIAM Journal on Scientific and Statistical Computing, 1981).
</DL>


<P>
@anchor{doc-cond}
<DL>
<DT><U>Function File:</U>  <B>cond</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX795"></A>
Compute the (two-norm) condition number of a matrix. <CODE>cond (a)</CODE> is
defined as <CODE>norm (a) * norm (inv (a))</CODE>, and is computed via a
singular value decomposition.
</DL>
@seealso{norm, svd, and rank}


<P>
@anchor{doc-det}
<DL>
<DT><U>Loadable Function:</U> [<VAR>d</VAR>, <VAR>rcond</VAR>] =  <B>det</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX796"></A>
Compute the determinant of <VAR>a</VAR> using LAPACK.  Return an estimate
of the reciprocal condition number if requested.
</DL>


<P>
@anchor{doc-dmult}
<DL>
<DT><U>Function File:</U>  <B>dmult</B> <I>(<VAR>a</VAR>, <VAR>b</VAR>)</I>
<DD><A NAME="IDX797"></A>
If <VAR>a</VAR> is a vector of length <CODE>rows (<VAR>b</VAR>)</CODE>, return
<CODE>diag (<VAR>a</VAR>) * <VAR>b</VAR></CODE> (but computed much more efficiently).
</DL>


<P>
@anchor{doc-dot}
<DL>
<DT><U>Function File:</U>  <B>dot</B> <I>(<VAR>x</VAR>, <VAR>y</VAR>)</I>
<DD><A NAME="IDX798"></A>
Computes the dot product of two vectors.
</DL>


<P>
@anchor{doc-eig}
<DL>
<DT><U>Loadable Function:</U> <VAR>lambda</VAR> = <B>eig</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX799"></A>
<DT><U>Loadable Function:</U> [<VAR>v</VAR>, <VAR>lambda</VAR>] = <B>eig</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX800"></A>
The eigenvalues (and eigenvectors) of a matrix are computed in a several
step process which begins with a Hessenberg decomposition, followed by a
Schur decomposition, from which the eigenvalues are apparent.  The
eigenvectors, when desired, are computed by further manipulations of the
Schur decomposition.
</DL>


<P>
@anchor{doc-givens}
<DL>
<DT><U>Loadable Function:</U> <VAR>g</VAR> = <B>givens</B> <I>(<VAR>x</VAR>, <VAR>y</VAR>)</I>
<DD><A NAME="IDX801"></A>
<DT><U>Loadable Function:</U> [<VAR>c</VAR>, <VAR>s</VAR>] = <B>givens</B> <I>(<VAR>x</VAR>, <VAR>y</VAR>)</I>
<DD><A NAME="IDX802"></A>
Return a 2 by 2 orthogonal matrix
<CODE><VAR>g</VAR> = [<VAR>c</VAR> <VAR>s</VAR>; -<VAR>s</VAR>' <VAR>c</VAR>]</CODE> such that
<CODE><VAR>g</VAR> [<VAR>x</VAR>; <VAR>y</VAR>] = [*; 0]</CODE> with <VAR>x</VAR> and <VAR>y</VAR> scalars.


<P>
For example,



<PRE>
givens (1, 1)
     =>   0.70711   0.70711
         -0.70711   0.70711
</PRE>

</DL>

<P>
@anchor{doc-inv}
<DL>
<DT><U>Loadable Function:</U> [<VAR>x</VAR>, <VAR>rcond</VAR>] =  <B>inv</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX803"></A>
<DT><U>Loadable Function:</U> [<VAR>x</VAR>, <VAR>rcond</VAR>] =  <B>inverse</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX804"></A>
Compute the inverse of the square matrix <VAR>a</VAR>.  Return an estimate
of the reciprocal condition number if requested, otherwise warn of an
ill-conditioned matrix if the reciprocal condition number is small.
</DL>


<P>
@anchor{doc-norm}
<DL>
<DT><U>Function File:</U>  <B>norm</B> <I>(<VAR>a</VAR>, <VAR>p</VAR>)</I>
<DD><A NAME="IDX805"></A>
Compute the p-norm of the matrix <VAR>a</VAR>.  If the second argument is
missing, <CODE>p = 2</CODE> is assumed.


<P>
If <VAR>a</VAR> is a matrix:


<DL COMPACT>

<DT><VAR>p</VAR> = <CODE>1</CODE>
<DD>
1-norm, the largest column sum of the absolute values of <VAR>a</VAR>.

<DT><VAR>p</VAR> = <CODE>2</CODE>
<DD>
Largest singular value of <VAR>a</VAR>.

<DT><VAR>p</VAR> = <CODE>Inf</CODE>
<DD>
<A NAME="IDX806"></A>
Infinity norm, the largest row sum of the absolute values of <VAR>a</VAR>.

<DT><VAR>p</VAR> = <CODE>"fro"</CODE>
<DD>
<A NAME="IDX807"></A>
Frobenius norm of <VAR>a</VAR>, <CODE>sqrt (sum (diag (<VAR>a</VAR>' * <VAR>a</VAR>)))</CODE>.
</DL>

<P>
If <VAR>a</VAR> is a vector or a scalar:


<DL COMPACT>

<DT><VAR>p</VAR> = <CODE>Inf</CODE>
<DD>
<CODE>max (abs (<VAR>a</VAR>))</CODE>.

<DT><VAR>p</VAR> = <CODE>-Inf</CODE>
<DD>
<CODE>min (abs (<VAR>a</VAR>))</CODE>.

<DT>other
<DD>
p-norm of <VAR>a</VAR>, <CODE>(sum (abs (<VAR>a</VAR>) .^ <VAR>p</VAR>)) ^ (1/<VAR>p</VAR>)</CODE>.
</DL>
</DL>
<P>
@seealso{cond and svd}


<P>
@anchor{doc-null}
<DL>
<DT><U>Function File:</U>  <B>null</B> <I>(<VAR>a</VAR>, <VAR>tol</VAR>)</I>
<DD><A NAME="IDX808"></A>
Return an orthonormal basis of the null space of <VAR>a</VAR>.


<P>
The dimension of the null space is taken as the number of singular
values of <VAR>a</VAR> not greater than <VAR>tol</VAR>.  If the argument <VAR>tol</VAR>
is missing, it is computed as



<PRE>
max (size (<VAR>a</VAR>)) * max (svd (<VAR>a</VAR>)) * eps
</PRE>

</DL>

<P>
@anchor{doc-orth}
<DL>
<DT><U>Function File:</U>  <B>orth</B> <I>(<VAR>a</VAR>, <VAR>tol</VAR>)</I>
<DD><A NAME="IDX809"></A>
Return an orthonormal basis of the range space of <VAR>a</VAR>.


<P>
The dimension of the range space is taken as the number of singular
values of <VAR>a</VAR> greater than <VAR>tol</VAR>.  If the argument <VAR>tol</VAR> is
missing, it is computed as



<PRE>
max (size (<VAR>a</VAR>)) * max (svd (<VAR>a</VAR>)) * eps
</PRE>

</DL>

<P>
@anchor{doc-pinv}
<DL>
<DT><U>Loadable Function:</U>  <B>pinv</B> <I>(<VAR>x</VAR>, <VAR>tol</VAR>)</I>
<DD><A NAME="IDX810"></A>
Return the pseudoinverse of <VAR>x</VAR>.  Singular values less than
<VAR>tol</VAR> are ignored. 


<P>
If the second argument is omitted, it is assumed that



<PRE>
tol = max (size (<VAR>x</VAR>)) * sigma_max (<VAR>x</VAR>) * eps,
</PRE>

<P>
where <CODE>sigma_max (<VAR>x</VAR>)</CODE> is the maximal singular value of <VAR>x</VAR>.
</DL>


<P>
@anchor{doc-rank}
<DL>
<DT><U>Function File:</U>  <B>rank</B> <I>(<VAR>a</VAR>, <VAR>tol</VAR>)</I>
<DD><A NAME="IDX811"></A>
Compute the rank of <VAR>a</VAR>, using the singular value decomposition.
The rank is taken to be the number  of singular values of <VAR>a</VAR> that
are greater than the specified tolerance <VAR>tol</VAR>.  If the second
argument is omitted, it is taken to be



<PRE>
tol = max (size (<VAR>a</VAR>)) * sigma(1) * eps;
</PRE>

<P>
where <CODE>eps</CODE> is machine precision and <CODE>sigma(1)</CODE> is the largest
singular value of <VAR>a</VAR>.
</DL>


<P>
@anchor{doc-trace}
<DL>
<DT><U>Function File:</U>  <B>trace</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX812"></A>
Compute the trace of <VAR>a</VAR>, <CODE>sum (diag (<VAR>a</VAR>))</CODE>.
</DL>




<H2><A NAME="SEC158" HREF="octave_toc.html#TOC158">Matrix Factorizations</A></H2>

<P>
@anchor{doc-chol}
<DL>
<DT><U>Loadable Function:</U>  <B>chol</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX813"></A>
<A NAME="IDX814"></A>
Compute the Cholesky factor, <VAR>r</VAR>, of the symmetric positive definite
matrix <VAR>a</VAR>, where



<PRE>
r' * r = a.
</PRE>

</DL>

<P>
@anchor{doc-hess}
<DL>
<DT><U>Loadable Function:</U> <VAR>h</VAR> = <B>hess</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX815"></A>
<DT><U>Loadable Function:</U> [<VAR>p</VAR>, <VAR>h</VAR>] = <B>hess</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX816"></A>
<A NAME="IDX817"></A>
Compute the Hessenberg decomposition of the matrix <VAR>a</VAR>.


<P>
The Hessenberg decomposition is usually used as the first step in an
eigenvalue computation, but has other applications as well (see Golub,
Nash, and Van Loan, IEEE Transactions on Automatic Control, 1979).  The
Hessenberg decomposition is
<CODE>p * h * p' = a</CODE> where <CODE>p</CODE> is a square unitary matrix
(<CODE>p' * p = I</CODE>, using complex-conjugate transposition) and <CODE>h</CODE>
is upper Hessenberg (<CODE>i &#62;= j+1 =&#62; h (i, j) = 0</CODE>).
</DL>


<P>
@anchor{doc-lu}
<DL>
<DT><U>Loadable Function:</U> [<VAR>l</VAR>, <VAR>u</VAR>, <VAR>p</VAR>] = <B>lu</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX818"></A>
<A NAME="IDX819"></A>
Compute the LU decomposition of <VAR>a</VAR>, using subroutines from
LAPACK.  The result is returned in a permuted form, according to
the optional return value <VAR>p</VAR>.  For example, given the matrix
<CODE>a = [1, 2; 3, 4]</CODE>,



<PRE>
[l, u, p] = lu (a)
</PRE>

<P>
returns



<PRE>
l =

  1.00000  0.00000
  0.33333  1.00000

u =

  3.00000  4.00000
  0.00000  0.66667

p =

  0  1
  1  0
</PRE>

<P>
The matrix is not required to be square..
</DL>


<P>
@anchor{doc-qr}
<DL>
<DT><U>Loadable Function:</U> [<VAR>q</VAR>, <VAR>r</VAR>, <VAR>p</VAR>] = <B>qr</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX820"></A>
<A NAME="IDX821"></A>
Compute the QR factorization of <VAR>a</VAR>, using standard LAPACK
subroutines.  For example, given the matrix <CODE>a = [1, 2; 3, 4]</CODE>,



<PRE>
[q, r] = qr (a)
</PRE>

<P>
returns



<PRE>
q =

  -0.31623  -0.94868
  -0.94868   0.31623

r =

  -3.16228  -4.42719
   0.00000  -0.63246
</PRE>

<P>
The <CODE>qr</CODE> factorization has applications in the solution of least
squares problems



<PRE>
<CODE>min norm(A x - b)</CODE>
</PRE>

<P>
for overdetermined systems of equations (i.e.,
<CODE>a</CODE>
 is a tall, thin matrix).  The QR factorization is
<CODE>q * r = a</CODE> where <CODE>q</CODE> is an orthogonal matrix and <CODE>r</CODE> is
upper triangular.


<P>
The permuted QR factorization <CODE>[<VAR>q</VAR>, <VAR>r</VAR>, <VAR>p</VAR>] =
qr (<VAR>a</VAR>)</CODE> forms the QR factorization such that the diagonal
entries of <CODE>r</CODE> are decreasing in magnitude order.  For example,
given the matrix <CODE>a = [1, 2; 3, 4]</CODE>,



<PRE>
[q, r, p] = qr(a)
</PRE>

<P>
returns



<PRE>
q = 

  -0.44721  -0.89443
  -0.89443   0.44721

r =

  -4.47214  -3.13050
   0.00000   0.44721

p =

   0  1
   1  0
</PRE>

<P>
The permuted <CODE>qr</CODE> factorization <CODE>[q, r, p] = qr (a)</CODE>
factorization allows the construction of an orthogonal basis of
<CODE>span (a)</CODE>.
</DL>


<P>
@anchor{doc-qz}
<DL>
<DT><U>Loadable Function:</U> <VAR>lambda</VAR> = <B>qz</B> <I>(<VAR>a</VAR>, <VAR>b</VAR>)</I>
<DD><A NAME="IDX822"></A>
Generalized eigenvalue problem <EM>A x = s B x</EM>,
<VAR>QZ</VAR> decomposition.  Three ways to call:

<OL>
<LI><CODE>lambda = qz(A,B)</CODE>

Computes the generalized eigenvalues <VAR>lambda</VAR> of <EM>(A - sB)</EM>.

<LI><CODE>[AA, BB, Q, Z, V, W, lambda] = qz (A, B)</CODE>

Computes qz decomposition, generalized eigenvectors, and 
        generalized eigenvalues of <EM>(A - sB)</EM>

<PRE>
        A V = B V diag(lambda)
        W' A = diag(lambda) W' B
        AA = Q'*A*Z, BB = Q'*B*Z  with Q, Z orthogonal (unitary)= I
</PRE>

<LI><CODE>[AA,BB,Z{,lambda}] = qz(A,B,opt)</CODE>

As in form [2], but allows ordering of generalized eigenpairs
        for (e.g.) solution of discrete time algebraic Riccati equations.
        Form 3 is not available for complex matrices and does not compute
        the generalized eigenvectors V, W, nor the orthogonal matrix Q.
<DL COMPACT>

<DT><VAR>opt</VAR>
<DD>
 for ordering eigenvalues of the GEP pencil.  The leading  block
             of the revised pencil contains all eigenvalues that satisfy:
<DL COMPACT>

<DT><CODE>"N"</CODE>
<DD>
 = unordered (default) 

<DT><CODE>"S"</CODE>
<DD>
= small: leading block has all |lambda| &#60;=1 

<DT><CODE>"B"</CODE>
<DD>
 = big: leading block has all |lambda &#62;= 1 

<DT><CODE>"-"</CODE>
<DD>
 = negative real part: leading  block has all eigenvalues
                  in the open left half-plant

<DT><CODE>"+"</CODE>
<DD>
 = nonnegative real part:  leading block has all eigenvalues
                  in the closed right half-plane
</DL>
</DL>
</OL>

<P>
Note: qz performs permutation balancing, but not scaling (see balance).
      Order of output arguments was selected for compatibility with MATLAB


<P>
See also: balance, dare, eig, schur
</DL>


<P>
@anchor{doc-qzhess}
<DL>
<DT><U>Function File:</U> [<VAR>aa</VAR>, <VAR>bb</VAR>, <VAR>q</VAR>, <VAR>z</VAR>] = <B>qzhess</B> <I>(<VAR>a</VAR>, <VAR>b</VAR>)</I>
<DD><A NAME="IDX823"></A>
Compute the Hessenberg-triangular decomposition of the matrix pencil
<CODE>(<VAR>a</VAR>, <VAR>b</VAR>)</CODE>, returning
<CODE><VAR>aa</VAR> = <VAR>q</VAR> * <VAR>a</VAR> * <VAR>z</VAR></CODE>,
<CODE><VAR>bb</VAR> = <VAR>q</VAR> * <VAR>b</VAR> * <VAR>z</VAR></CODE>, with <VAR>q</VAR> and <VAR>z</VAR>
orthogonal.  For example,



<PRE>
[aa, bb, q, z] = qzhess ([1, 2; 3, 4], [5, 6; 7, 8])
=> aa = [ -3.02244, -4.41741;  0.92998,  0.69749 ]
=> bb = [ -8.60233, -9.99730;  0.00000, -0.23250 ]
=>  q = [ -0.58124, -0.81373; -0.81373,  0.58124 ]
=>  z = [ 1, 0; 0, 1 ]
</PRE>

<P>
The Hessenberg-triangular decomposition is the first step in
Moler and Stewart's QZ decomposition algorithm.


<P>
Algorithm taken from Golub and Van Loan, <CITE>Matrix Computations, 2nd
edition</CITE>.
</DL>


<P>
@anchor{doc-schur}
<DL>
<DT><U>Loadable Function:</U> <VAR>s</VAR> = <B>schur</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX824"></A>
<DT><U>Loadable Function:</U> [<VAR>u</VAR>, <VAR>s</VAR>] = <B>schur</B> <I>(<VAR>a</VAR>, <VAR>opt</VAR>)</I>
<DD><A NAME="IDX825"></A>
<A NAME="IDX826"></A>
The Schur decomposition is used to compute eigenvalues of a
square matrix, and has applications in the solution of algebraic
Riccati equations in control (see <CODE>are</CODE> and <CODE>dare</CODE>).
<CODE>schur</CODE> always returns
<CODE>s = u' * a * u</CODE>
where
<CODE>u</CODE>
 is a unitary matrix
(<CODE>u'* u</CODE> is identity)
and
<CODE>s</CODE>
is upper triangular.  The eigenvalues of
<CODE>a</CODE> (and <CODE>s</CODE>)
are the diagonal elements of
<CODE>s</CODE>
If the matrix
<CODE>a</CODE>
is real, then the real Schur decomposition is computed, in which the
matrix
<CODE>u</CODE>
is orthogonal and
<CODE>s</CODE>
is block upper triangular
with blocks of size at most
<CODE>2 x 2</CODE>
along the diagonal.  The diagonal elements of
<CODE>s</CODE>
(or the eigenvalues of the
<CODE>2 x 2</CODE>
blocks, when
appropriate) are the eigenvalues of
<CODE>a</CODE>
and
<CODE>s</CODE>.


<P>
The eigenvalues are optionally ordered along the diagonal according to
the value of <CODE>opt</CODE>.  <CODE>opt = "a"</CODE> indicates that all
eigenvalues with negative real parts should be moved to the leading
block of
<CODE>s</CODE>
(used in <CODE>are</CODE>), <CODE>opt = "d"</CODE> indicates that all eigenvalues
with magnitude less than one should be moved to the leading block of
<CODE>s</CODE>
(used in <CODE>dare</CODE>), and <CODE>opt = "u"</CODE>, the default, indicates that
no ordering of eigenvalues should occur.  The leading
<CODE>k</CODE>
columns of
<CODE>u</CODE>
always span the
<CODE>a</CODE>-invariant
subspace corresponding to the
<CODE>k</CODE>
leading eigenvalues of
<CODE>s</CODE>.
</DL>


<P>
@anchor{doc-svd}
<DL>
<DT><U>Loadable Function:</U> <VAR>s</VAR> = <B>svd</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX827"></A>
<DT><U>Loadable Function:</U> [<VAR>u</VAR>, <VAR>s</VAR>, <VAR>v</VAR>] = <B>svd</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX828"></A>
<A NAME="IDX829"></A>
Compute the singular value decomposition of <VAR>a</VAR>



<PRE>
a = u * sigma * v'
</PRE>

<P>
The function <CODE>svd</CODE> normally returns the vector of singular values.
If asked for three return values, it computes
U, S, and V.
For example,



<PRE>
svd (hilb (3))
</PRE>

<P>
returns



<PRE>
ans =

  1.4083189
  0.1223271
  0.0026873
</PRE>

<P>
and



<PRE>
[u, s, v] = svd (hilb (3))
</PRE>

<P>
returns



<PRE>
u =

  -0.82704   0.54745   0.12766
  -0.45986  -0.52829  -0.71375
  -0.32330  -0.64901   0.68867

s =

  1.40832  0.00000  0.00000
  0.00000  0.12233  0.00000
  0.00000  0.00000  0.00269

v =

  -0.82704   0.54745   0.12766
  -0.45986  -0.52829  -0.71375
  -0.32330  -0.64901   0.68867
</PRE>

<P>
If given a second argument, <CODE>svd</CODE> returns an economy-sized
decomposition, eliminating the unnecessary rows or columns of <VAR>u</VAR> or
<VAR>v</VAR>.
</DL>


<P>
@anchor{doc-housh}
<DL>
<DT><U>Function File:</U> [<VAR>housv</VAR>, <VAR>beta</VAR>, <VAR>zer</VAR>] = <B>housh</B> <I>(<VAR>x</VAR>, <VAR>j</VAR>, <VAR>z</VAR>)</I>
<DD><A NAME="IDX830"></A>
Computes householder reflection vector housv to reflect x to be
jth column of identity, i.e., (I - beta*housv*housv')x =e(j)
inputs
  x: vector
  j: index into vector
  z: threshold for zero  (usually should be the number 0)
outputs: (see Golub and Van Loan)
  beta: If beta = 0, then no reflection need be applied (zer set to 0)
  housv: householder vector
</DL>


<P>
@anchor{doc-krylov}
<DL>
<DT><U>Function File:</U> [<VAR>u</VAR>, <VAR>h</VAR>, <VAR>nu</VAR>] = <B>krylov</B> <I>(<VAR>a</VAR>, <VAR>v</VAR>, <VAR>k</VAR>, <VAR>eps1</VAR>, <VAR>pflg</VAR>);</I>
<DD><A NAME="IDX831"></A>
construct orthogonal basis U of block Krylov subspace;
 [v a*v a^2*v ... a^(k+1)*v];
method used: householder reflections to guard against loss of
orthogonality
eps1: threshhold for 0 (default: 1e-12)
pflg: flag to use row pivoting  (improves numerical behavior)
  0 [default]: no pivoting; prints a warning message if trivial
               null space is corrupted
  1          : pivoting performed


<P>
outputs:
  u: orthogonal basis of block krylov subspace
  h: Hessenberg matrix; if v is a vector then a u = u h
     otherwise h is meaningless
 nu: dimension of span of krylov subspace (based on eps1)
if b is a vector and k &#62; m-1, krylov returns h = the Hessenberg
decompostion of a.


<P>
Reference: Hodel and Misra, "Partial Pivoting in the Computation of
    Krylov Subspaces", to be submitted to Linear Algebra and its
    Applications
</DL>




<H2><A NAME="SEC159" HREF="octave_toc.html#TOC159">Functions of a Matrix</A></H2>

<P>
@anchor{doc-expm}
<DL>
<DT><U>Loadable Function:</U>  <B>expm</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX832"></A>
Return the exponential of a matrix, defined as the infinite Taylor
series



<PRE>
expm(a) = I + a + a^2/2! + a^3/3! + ...
</PRE>

<P>
The Taylor series is <EM>not</EM> the way to compute the matrix
exponential; see Moler and Van Loan, <CITE>Nineteen Dubious Ways to
Compute the Exponential of a Matrix</CITE>, SIAM Review, 1978.  This routine
uses Ward's diagonal
Pade'
approximation method with three step preconditioning (SIAM Journal on
Numerical Analysis, 1977).  Diagonal
Pade'
 approximations are rational polynomials of matrices



<PRE>
     -1
D (a)   N (a)
</PRE>

<P>
 whose Taylor series matches the first
<CODE>2q+1</CODE>
terms of the Taylor series above; direct evaluation of the Taylor series
(with the same preconditioning steps) may be desirable in lieu of the
Pade'
approximation when
<CODE>Dq(a)</CODE>
is ill-conditioned.
</DL>


<P>
@anchor{doc-logm}
<DL>
<DT><U>Function File:</U>  <B>logm</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX833"></A>
Compute the matrix logarithm of the square matrix <VAR>a</VAR>.  Note that
this is currently implemented in terms of an eigenvalue expansion and
needs to be improved to be more robust.
</DL>


<P>
@anchor{doc-sqrtm}
<DL>
<DT><U>Loadable Function:</U> [<VAR>result</VAR>, <VAR>error_estimate</VAR>] = <B>sqrtm</B> <I>(<VAR>a</VAR>)</I>
<DD><A NAME="IDX834"></A>
Compute the matrix square root of the square matrix <VAR>a</VAR>.


<P>
Ref: Nicholas J. Higham. A new sqrtm for MATLAB. Numerical Analysis
Report No. 336, Manchester Centre for Computational Mathematics,
Manchester, England, January 1999.
</DL>
@seealso{expm, logm, and funm}


<P>
@anchor{doc-kron}
<DL>
<DT><U>Function File:</U>  <B>kron</B> <I>(<VAR>a</VAR>, <VAR>b</VAR>)</I>
<DD><A NAME="IDX835"></A>
Form the kronecker product of two matrices, defined block by block as



<PRE>
x = [a(i, j) b]
</PRE>

<P>
For example,



<PRE>
kron (1:4, ones (3, 1))
      =>  1  2  3  4
          1  2  3  4
          1  2  3  4
</PRE>

</DL>

<P>
@anchor{doc-syl}
<DL>
<DT><U>Loadable Function:</U> <VAR>x</VAR> = <B>syl</B> <I>(<VAR>a</VAR>, <VAR>b</VAR>, <VAR>c</VAR>)</I>
<DD><A NAME="IDX836"></A>
Solve the Sylvester equation



<PRE>
A X + X B + C = 0
</PRE>

<P>
using standard LAPACK subroutines.  For example,



<PRE>
syl ([1, 2; 3, 4], [5, 6; 7, 8], [9, 10; 11, 12])
     => [ -0.50000, -0.66667; -0.66667, -0.50000 ]
</PRE>

</DL>

<P><HR><P>
Go to the <A HREF="octave_1.html">first</A>, <A HREF="octave_20.html">previous</A>, <A HREF="octave_22.html">next</A>, <A HREF="octave_45.html">last</A> section, <A HREF="octave_toc.html">table of contents</A>.
</BODY>
</HTML>
